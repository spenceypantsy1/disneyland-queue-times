{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5200dce",
   "metadata": {},
   "source": [
    "# Combining raw dataframes information together to form a master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf7da018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "using waiting_times as the base for master as it contains \n",
    "all relevant information for attraction specific wait times\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "master = pd.read_parquet(\"../data/raw_data/waiting_times.parquet\")\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |  link attraction park merging   |\n",
    "# ===================================\n",
    "\n",
    "# link attraction park to label which attraction belongoning to which park\n",
    "link_attraction_park = pd.read_parquet(\"../data/processed_data/link_attraction_park.parquet\")\n",
    "master_merged_1 = master.merge(link_attraction_park, left_on = 'ENTITY_DESCRIPTION_SHORT', right_on = 'ATTRACTION', how = 'left')\n",
    "\n",
    "# replacing ENTITY_DESCRIPTION_SHORT with ATTRACTION for clarity\n",
    "master_merged_1.drop(columns = ['ENTITY_DESCRIPTION_SHORT'], inplace = True)  \n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |           attendance            |\n",
    "# ===================================\n",
    "\n",
    "# link attendance to mark attendance for each park and date. this way wait times will have daily attendance\n",
    "attendance = pd.read_parquet(\"../data/raw_data/attendance.parquet\")\n",
    "\n",
    "# converting datetimes to datetime format\n",
    "attendance['USAGE_DATE'] = pd.to_datetime(attendance['USAGE_DATE'])\n",
    "master_merged_1['WORK_DATE'] = pd.to_datetime(master_merged_1['WORK_DATE'])\n",
    "\n",
    "master_merged_2 = master_merged_1.merge(attendance, left_on = ['PARK', 'WORK_DATE'], right_on = ['FACILITY_NAME', 'USAGE_DATE'], how = 'left')\n",
    "#! there are a bunch of dates that dont have attendance data, keep for now\n",
    "\n",
    "# removing FACILITY_NAME and USAGE_DATE since redundant after merge\n",
    "master_merged_2.drop(columns = ['FACILITY_NAME', 'USAGE_DATE'], inplace = True)\n",
    "master_merged_2\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |         weather data            |\n",
    "# ===================================\n",
    "\n",
    "# link weather data to mark weather for each park and date. this way wait times will have daily weather\n",
    "weather_data = pd.read_parquet(\"../data/raw_data/weather_data.parquet\")\n",
    "\n",
    "# weather data time is in iso format and UTC, converting it to datetime with timezone offset\n",
    "weather_data['dt_iso'] = pd.to_datetime(weather_data['dt'], unit = 's') + pd.to_timedelta(weather_data['timezone'], unit='s')\n",
    "\n",
    "master_merged_3 = master_merged_2.merge(weather_data, left_on = 'WORK_DATE', right_on = 'dt_iso', how = 'left')\n",
    "\n",
    "# removing all redundant datetime/ timeszone/ location columns\n",
    "master_merged_3.drop(columns = ['dt', 'dt_iso', 'timezone', 'city_name', 'lat', 'lon'], inplace = True)\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |        entity schedule          |\n",
    "# ===================================\n",
    "\n",
    "# link entity schedule to indicate when there are closures for whichever attraction\n",
    "entity_schedule = pd.read_parquet(\"../data/raw_data/entity_schedule.parquet\")\n",
    "\n",
    "# creating a subset so i dont merge the entire entity schedule with redundant columns\n",
    "entity_schedule_subset = entity_schedule[['REF_CLOSING_DESCRIPTION', 'ENTITY_DESCRIPTION_SHORT', 'WORK_DATE']].copy()\n",
    "\n",
    "# converting datetimes to datetime format\n",
    "entity_schedule_subset['WORK_DATE'] = pd.to_datetime(entity_schedule_subset['WORK_DATE'])\n",
    "\n",
    "master_merged_4 = master_merged_3.merge(entity_schedule_subset, left_on = ['ATTRACTION', 'WORK_DATE'], right_on = ['ENTITY_DESCRIPTION_SHORT', 'WORK_DATE'], how = 'left')\n",
    "\n",
    "# dropping redundant merge columns\n",
    "master_merged_4.drop(columns = ['ENTITY_DESCRIPTION_SHORT'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1b487e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_merged_4.to_parquet('../data/processed_data/all_raw_combined.parquet', index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e422b8",
   "metadata": {},
   "source": [
    "# Removed columns that are primarily NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b7fa7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['visibility', 'sea_level', 'grnd_level', 'wind_gust', 'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORK_DATE</th>\n",
       "      <th>DEB_TIME</th>\n",
       "      <th>DEB_TIME_HOUR</th>\n",
       "      <th>FIN_TIME</th>\n",
       "      <th>WAIT_TIME_MAX</th>\n",
       "      <th>NB_UNITS</th>\n",
       "      <th>GUEST_CARRIED</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>ADJUST_CAPACITY</th>\n",
       "      <th>OPEN_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "      <th>REF_CLOSING_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 21:00:00.000</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-01-01 21:15:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1007</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 19:30:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-01-01 19:45:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>254.749</td>\n",
       "      <td>254.75</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1007</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 22:30:00.000</td>\n",
       "      <td>22</td>\n",
       "      <td>2018-01-01 22:45:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1007</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 12:45:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-01-01 13:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.001</td>\n",
       "      <td>250.00</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1007</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 17:00:00.000</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-01-01 17:15:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>211.500</td>\n",
       "      <td>198.25</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1007</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORK_DATE                 DEB_TIME  DEB_TIME_HOUR                 FIN_TIME  \\\n",
       "0 2018-01-01  2018-01-01 21:00:00.000             21  2018-01-01 21:15:00.000   \n",
       "1 2018-01-01  2018-01-01 19:30:00.000             19  2018-01-01 19:45:00.000   \n",
       "2 2018-01-01  2018-01-01 22:30:00.000             22  2018-01-01 22:45:00.000   \n",
       "3 2018-01-01  2018-01-01 12:45:00.000             12  2018-01-01 13:00:00.000   \n",
       "4 2018-01-01  2018-01-01 17:00:00.000             17  2018-01-01 17:15:00.000   \n",
       "\n",
       "   WAIT_TIME_MAX  NB_UNITS  GUEST_CARRIED  CAPACITY  ADJUST_CAPACITY  \\\n",
       "0              0       2.0            0.0     0.000             0.00   \n",
       "1              5      18.0          148.0   254.749           254.75   \n",
       "2              0       1.0            0.0     0.000             0.00   \n",
       "3              5       1.0           46.0   250.001           250.00   \n",
       "4              5      15.0           92.0   211.500           198.25   \n",
       "\n",
       "   OPEN_TIME  ...  pressure  humidity  wind_speed wind_deg clouds_all  \\\n",
       "0          0  ...      1007        76        7.94      231         34   \n",
       "1         15  ...      1007        76        7.94      231         34   \n",
       "2          0  ...      1007        76        7.94      231         34   \n",
       "3         15  ...      1007        76        7.94      231         34   \n",
       "4         15  ...      1007        76        7.94      231         34   \n",
       "\n",
       "   weather_id  weather_main  weather_description  weather_icon  \\\n",
       "0         802        Clouds     scattered clouds           03n   \n",
       "1         802        Clouds     scattered clouds           03n   \n",
       "2         802        Clouds     scattered clouds           03n   \n",
       "3         802        Clouds     scattered clouds           03n   \n",
       "4         802        Clouds     scattered clouds           03n   \n",
       "\n",
       "   REF_CLOSING_DESCRIPTION  \n",
       "0               No Closure  \n",
       "1               No Closure  \n",
       "2               No Closure  \n",
       "3               No Closure  \n",
       "4               No Closure  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all columns that are majority NA except for REF_CLOSING_DESCRIPTION\n",
    "master_merged_4['REF_CLOSING_DESCRIPTION'] = master_merged_4['REF_CLOSING_DESCRIPTION'].fillna('No Closure')\n",
    "\n",
    "# now removing all columns that are majority NA\n",
    "threshold = 0.8\n",
    "cols_to_drop = master_merged_4.columns[master_merged_4.isna().sum() / len(master_merged_4) > threshold]\n",
    "df = master_merged_4.drop(columns = cols_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {cols_to_drop.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b75ff",
   "metadata": {},
   "source": [
    "# Remove extreme outliers for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42b2d6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DEB_TIME_HOUR' has 0 outliers\n",
      "Column 'WAIT_TIME_MAX' has 48299 outliers\n",
      "Column 'NB_UNITS' has 200686 outliers\n",
      "Column 'GUEST_CARRIED' has 19279 outliers\n",
      "Column 'CAPACITY' has 0 outliers\n",
      "Column 'ADJUST_CAPACITY' has 0 outliers\n",
      "Column 'OPEN_TIME' has 0 outliers\n",
      "Column 'UP_TIME' has 0 outliers\n",
      "Column 'DOWNTIME' has 79346 outliers\n",
      "Column 'NB_MAX_UNIT' has 108040 outliers\n",
      "Column 'attendance' has 0 outliers\n",
      "Column 'temp' has 0 outliers\n",
      "Column 'dew_point' has 0 outliers\n",
      "Column 'feels_like' has 0 outliers\n",
      "Column 'temp_min' has 0 outliers\n",
      "Column 'temp_max' has 0 outliers\n",
      "Column 'pressure' has 0 outliers\n",
      "Column 'humidity' has 0 outliers\n",
      "Column 'wind_speed' has 6975 outliers\n",
      "Column 'wind_deg' has 0 outliers\n",
      "Column 'clouds_all' has 0 outliers\n",
      "Column 'weather_id' has 207926 outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORK_DATE</th>\n",
       "      <th>DEB_TIME</th>\n",
       "      <th>DEB_TIME_HOUR</th>\n",
       "      <th>FIN_TIME</th>\n",
       "      <th>WAIT_TIME_MAX</th>\n",
       "      <th>NB_UNITS</th>\n",
       "      <th>GUEST_CARRIED</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>ADJUST_CAPACITY</th>\n",
       "      <th>OPEN_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "      <th>REF_CLOSING_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312872</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 19:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-06-01 19:15:00.000</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1018</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312873</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 15:00:00.000</td>\n",
       "      <td>15</td>\n",
       "      <td>2018-06-01 15:15:00.000</td>\n",
       "      <td>30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>280.50</td>\n",
       "      <td>263.50</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1018</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312874</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 20:30:00.000</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-06-01 20:45:00.000</td>\n",
       "      <td>40</td>\n",
       "      <td>12.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>101.25</td>\n",
       "      <td>101.25</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1018</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312875</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 16:30:00.000</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-06-01 16:45:00.000</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>526.25</td>\n",
       "      <td>438.50</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1018</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312877</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 13:45:00.000</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-06-01 14:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1018</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>Fermeture Opérationnelle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WORK_DATE                 DEB_TIME  DEB_TIME_HOUR  \\\n",
       "312872 2018-06-01  2018-06-01 19:00:00.000             19   \n",
       "312873 2018-06-01  2018-06-01 15:00:00.000             15   \n",
       "312874 2018-06-01  2018-06-01 20:30:00.000             20   \n",
       "312875 2018-06-01  2018-06-01 16:30:00.000             16   \n",
       "312877 2018-06-01  2018-06-01 13:45:00.000             13   \n",
       "\n",
       "                       FIN_TIME  WAIT_TIME_MAX  NB_UNITS  GUEST_CARRIED  \\\n",
       "312872  2018-06-01 19:15:00.000             15       2.0           50.0   \n",
       "312873  2018-06-01 15:15:00.000             30      62.0          155.0   \n",
       "312874  2018-06-01 20:45:00.000             40      12.0           69.0   \n",
       "312875  2018-06-01 16:45:00.000             15       5.0          283.0   \n",
       "312877  2018-06-01 14:00:00.000              0       0.0            0.0   \n",
       "\n",
       "        CAPACITY  ADJUST_CAPACITY  OPEN_TIME  ...  pressure  humidity  \\\n",
       "312872     75.00            75.00         15  ...      1018        94   \n",
       "312873    280.50           263.50         15  ...      1018        94   \n",
       "312874    101.25           101.25         15  ...      1018        94   \n",
       "312875    526.25           438.50         15  ...      1018        94   \n",
       "312877      0.00             0.00          0  ...      1018        94   \n",
       "\n",
       "        wind_speed wind_deg clouds_all  weather_id  weather_main  \\\n",
       "312872        1.54      200         99         804        Clouds   \n",
       "312873        1.54      200         99         804        Clouds   \n",
       "312874        1.54      200         99         804        Clouds   \n",
       "312875        1.54      200         99         804        Clouds   \n",
       "312877        1.54      200         99         804        Clouds   \n",
       "\n",
       "        weather_description  weather_icon   REF_CLOSING_DESCRIPTION  \n",
       "312872      overcast clouds           04n                No Closure  \n",
       "312873      overcast clouds           04n                No Closure  \n",
       "312874      overcast clouds           04n                No Closure  \n",
       "312875      overcast clouds           04n                No Closure  \n",
       "312877      overcast clouds           04n  Fermeture Opérationnelle  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "filtering out extreme outliers for numerical features by\n",
    "removing any data points outside of 3*IQR\n",
    "\"\"\"\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# get numerical columns\n",
    "numerical_cols = df_clean.select_dtypes(include=['number']).columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 3 * IQR\n",
    "    upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "    # count outliers before removal\n",
    "    outlier_count = len(df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)])\n",
    "    print(f\"Column '{col}' has {outlier_count} outliers\")\n",
    "\n",
    "    # remove the outliers\n",
    "    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6d870",
   "metadata": {},
   "source": [
    "# Scaling our numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72271623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\script.pc #93\\AppData\\Local\\Temp\\ipykernel_28668\\3501286311.py:7: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inbalanced Columns: ['PARK', 'weather_main', 'weather_description', 'weather_icon', 'REF_CLOSING_DESCRIPTION']\n"
     ]
    }
   ],
   "source": [
    "# finding imbalanced categories\n",
    "\n",
    "# converting datetime strings into datetime dtype\n",
    "df_clean['DEB_TIME'] = pd.to_datetime(df_clean['DEB_TIME'])\n",
    "df_clean['FIN_TIME'] = pd.to_datetime(df_clean['FIN_TIME'])\n",
    "\n",
    "categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "imbalanced_cols = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    value_count = df_clean[col].value_counts()\n",
    "    percentages = value_count / len(df_clean) * 100\n",
    "\n",
    "    # check highest occuring class vs the lowest occuring class\n",
    "    imbalance_ratio = (percentages.max() - percentages.min())\n",
    "\n",
    "    # check if imbalance ratio is > 5 times\n",
    "    if imbalance_ratio >5:\n",
    "        # if imbalanced, append to list\n",
    "        imbalanced_cols.append(col)\n",
    "\n",
    "print(f\"Inbalanced Columns: {imbalanced_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d583c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1893178, 31)\n",
      "Train set shape: (1135906, 31)\n",
      "Validation set shape: (378636, 31)\n",
      "Test set shape: (378636, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split our data before scaling to avoid data leakage\n",
    "train_df, test_df = train_test_split(df_clean, \n",
    "                                     test_size=0.4, \n",
    "                                     random_state=42, \n",
    "                                     stratify = df_clean[['PARK', 'weather_main', 'weather_description', 'weather_icon', 'REF_CLOSING_DESCRIPTION']])\n",
    "\n",
    "val_df, test_df = train_test_split(test_df, \n",
    "                                   test_size=0.5,\n",
    "                                   random_state=42,\n",
    "                                   stratify = test_df[['PARK', 'weather_main', 'weather_description', 'weather_icon', 'REF_CLOSING_DESCRIPTION']])\n",
    "\n",
    "print(f\"Original shape: {df_clean.shape}\")\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Validation set shape: {val_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e8ae9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WORK_DATE', 'DEB_TIME', 'DEB_TIME_HOUR', 'FIN_TIME', 'WAIT_TIME_MAX',\n",
       "       'NB_UNITS', 'GUEST_CARRIED', 'CAPACITY', 'ADJUST_CAPACITY', 'OPEN_TIME',\n",
       "       'UP_TIME', 'DOWNTIME', 'NB_MAX_UNIT', 'ATTRACTION', 'PARK',\n",
       "       'attendance', 'temp', 'dew_point', 'feels_like', 'temp_min', 'temp_max',\n",
       "       'pressure', 'humidity', 'wind_speed', 'wind_deg', 'clouds_all',\n",
       "       'weather_id', 'weather_main', 'weather_description', 'weather_icon',\n",
       "       'REF_CLOSING_DESCRIPTION'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1135906, 22)\n",
      "Validation set shape: (378636, 22)\n",
      "Test set shape: (378636, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_cols = train_df.select_dtypes(include=['number']).columns\n",
    "# even though its numeric it should be treated as categorical\n",
    "numerical_cols = numerical_cols.drop('DEB_TIME_HOUR')\n",
    "\n",
    "# scale fit on train set ONLY\n",
    "train_df_scaled = scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "# scale transform on val and test set using the same scaler fit on train set\n",
    "val_df_scaled = scaler.transform(val_df[numerical_cols])\n",
    "test_df_scaled = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "train_df_scaled = pd.DataFrame(train_df_scaled, columns = numerical_cols, index = train_df.index)\n",
    "val_df_scaled = pd.DataFrame(val_df_scaled, columns = numerical_cols, index = val_df.index)\n",
    "test_df_scaled = pd.DataFrame(test_df_scaled, columns = numerical_cols, index = test_df.index)\n",
    "\n",
    "print(f\"Train set shape: {train_df_scaled.shape}\")\n",
    "print(f\"Validation set shape: {val_df_scaled.shape}\")\n",
    "print(f\"Test set shape: {test_df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164bc77",
   "metadata": {},
   "source": [
    "# Categorical Encoding\n",
    "One hot encoding because we don't have any ordinal categories for ordinal or binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4c7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\script.pc #93\\AppData\\Local\\Temp\\ipykernel_28668\\874799718.py:3: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1135906, 46)\n",
      "Validation set shape: (378636, 46)\n",
      "Test set shape: (378636, 46)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
    "# adding hours to categorical\n",
    "categorical_cols = categorical_cols.append('DEB_TIME_HOUR')\n",
    "\n",
    "# fit OHE on the train set ONLY\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore', drop = 'first')\n",
    "train_df_ohe = ohe.fit_transform(train_df[categorical_cols])\n",
    "\n",
    "# transform val and test set using the same OHE fit on train set\n",
    "val_df_ohe = ohe.transform(val_df[categorical_cols])\n",
    "test_df_ohe = ohe.transform(test_df[categorical_cols])\n",
    "\n",
    "# transform ohe matrices into dataframes\n",
    "ohe_columns = ohe.get_feature_names_out(categorical_cols)\n",
    "train_df_ohe = pd.DataFrame(train_df_ohe.toarray(), columns = ohe_columns, index = train_df.index)\n",
    "val_df_ohe = pd.DataFrame(val_df_ohe.toarray(), columns=ohe_columns, index = val_df.index)\n",
    "test_df_ohe = pd.DataFrame(test_df_ohe.toarray(), columns=ohe_columns, index = test_df.index)\n",
    "\n",
    "print(f\"Train set shape: {train_df_ohe.shape}\")\n",
    "print(f\"Validation set shape: {val_df_ohe.shape}\")\n",
    "print(f\"Test set shape: {test_df_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fa73e",
   "metadata": {},
   "source": [
    "# Combining Scaled and Encoded Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530b42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
