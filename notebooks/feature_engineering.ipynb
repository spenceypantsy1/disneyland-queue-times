{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5200dce",
   "metadata": {},
   "source": [
    "# Combining raw dataframes information together to form a master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7da018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "using waiting_times as the base for master as it contains \n",
    "all relevant information for attraction specific wait times\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "master = pd.read_parquet(\"../data/raw_data/waiting_times.parquet\")\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |  link attraction park merging   |\n",
    "# ===================================\n",
    "\n",
    "# link attraction park to label which attraction belongoning to which park\n",
    "link_attraction_park = pd.read_parquet(\"../data/processed_data/link_attraction_park.parquet\")\n",
    "master_merged_1 = master.merge(link_attraction_park, left_on = 'ENTITY_DESCRIPTION_SHORT', right_on = 'ATTRACTION', how = 'left')\n",
    "\n",
    "# replacing ENTITY_DESCRIPTION_SHORT with ATTRACTION for clarity\n",
    "master_merged_1.drop(columns = ['ENTITY_DESCRIPTION_SHORT'], inplace = True)  \n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |           attendance            |\n",
    "# ===================================\n",
    "\n",
    "# link attendance to mark attendance for each park and date. this way wait times will have daily attendance\n",
    "attendance = pd.read_parquet(\"../data/raw_data/attendance.parquet\")\n",
    "\n",
    "# converting datetimes to datetime format\n",
    "attendance['USAGE_DATE'] = pd.to_datetime(attendance['USAGE_DATE'])\n",
    "master_merged_1['WORK_DATE'] = pd.to_datetime(master_merged_1['WORK_DATE'])\n",
    "\n",
    "master_merged_2 = master_merged_1.merge(attendance, left_on = ['PARK', 'WORK_DATE'], right_on = ['FACILITY_NAME', 'USAGE_DATE'], how = 'left')\n",
    "#! there are a bunch of dates that dont have attendance data, keep for now\n",
    "\n",
    "# removing FACILITY_NAME and USAGE_DATE since redundant after merge\n",
    "master_merged_2.drop(columns = ['FACILITY_NAME', 'USAGE_DATE'], inplace = True)\n",
    "master_merged_2\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |         weather data            |\n",
    "# ===================================\n",
    "\n",
    "# link weather data to mark weather for each park and date. this way wait times will have daily weather\n",
    "weather_data = pd.read_parquet(\"../data/raw_data/weather_data.parquet\")\n",
    "\n",
    "# weather data time is in iso format and UTC, converting it to datetime with timezone offset\n",
    "weather_data['dt_iso'] = pd.to_datetime(weather_data['dt'], unit = 's') + pd.to_timedelta(weather_data['timezone'], unit='s')\n",
    "\n",
    "master_merged_3 = master_merged_2.merge(weather_data, left_on = 'WORK_DATE', right_on = 'dt_iso', how = 'left')\n",
    "\n",
    "# removing all redundant datetime/ timeszone/ location columns\n",
    "master_merged_3.drop(columns = ['dt', 'dt_iso', 'timezone', 'city_name', 'lat', 'lon'], inplace = True)\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# |        entity schedule          |\n",
    "# ===================================\n",
    "\n",
    "# link entity schedule to indicate when there are closures for whichever attraction\n",
    "entity_schedule = pd.read_parquet(\"../data/raw_data/entity_schedule.parquet\")\n",
    "\n",
    "# creating a subset so i dont merge the entire entity schedule with redundant columns\n",
    "entity_schedule_subset = entity_schedule[['REF_CLOSING_DESCRIPTION', 'ENTITY_DESCRIPTION_SHORT', 'WORK_DATE']].copy()\n",
    "\n",
    "# converting datetimes to datetime format\n",
    "entity_schedule_subset['WORK_DATE'] = pd.to_datetime(entity_schedule_subset['WORK_DATE'])\n",
    "\n",
    "master_merged_4 = master_merged_3.merge(entity_schedule_subset, left_on = ['ATTRACTION', 'WORK_DATE'], right_on = ['ENTITY_DESCRIPTION_SHORT', 'WORK_DATE'], how = 'left')\n",
    "\n",
    "# dropping redundant merge columns\n",
    "master_merged_4.drop(columns = [ 'ENTITY_DESCRIPTION_SHORT'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f530b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_merged_4.to_parquet('../data/processed_data/master.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a6bee",
   "metadata": {},
   "source": [
    "# Adding Months feature from WORK_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436258e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning WORK_DATE into datetime then extracting months as a feature\n",
    "master_merged_4['WORK_DATE'] = pd.to_datetime(master_merged_4['WORK_DATE'])\n",
    "master_merged_4['month'] = master_merged_4['WORK_DATE'].dt.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee889e1a",
   "metadata": {},
   "source": [
    "# Removed columns that are primarily NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470b2d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['visibility', 'sea_level', 'grnd_level', 'wind_gust', 'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORK_DATE</th>\n",
       "      <th>DEB_TIME</th>\n",
       "      <th>DEB_TIME_HOUR</th>\n",
       "      <th>FIN_TIME</th>\n",
       "      <th>WAIT_TIME_MAX</th>\n",
       "      <th>NB_UNITS</th>\n",
       "      <th>GUEST_CARRIED</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>ADJUST_CAPACITY</th>\n",
       "      <th>OPEN_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "      <th>REF_CLOSING_DESCRIPTION</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 21:00:00.000</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-01-01 21:15:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 19:30:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-01-01 19:45:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>254.749</td>\n",
       "      <td>254.75</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 22:30:00.000</td>\n",
       "      <td>22</td>\n",
       "      <td>2018-01-01 22:45:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 12:45:00.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-01-01 13:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.001</td>\n",
       "      <td>250.00</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 17:00:00.000</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-01-01 17:15:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>211.500</td>\n",
       "      <td>198.25</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>7.94</td>\n",
       "      <td>231</td>\n",
       "      <td>34</td>\n",
       "      <td>802</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>03n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WORK_DATE                 DEB_TIME  DEB_TIME_HOUR                 FIN_TIME  \\\n",
       "0 2018-01-01  2018-01-01 21:00:00.000             21  2018-01-01 21:15:00.000   \n",
       "1 2018-01-01  2018-01-01 19:30:00.000             19  2018-01-01 19:45:00.000   \n",
       "2 2018-01-01  2018-01-01 22:30:00.000             22  2018-01-01 22:45:00.000   \n",
       "3 2018-01-01  2018-01-01 12:45:00.000             12  2018-01-01 13:00:00.000   \n",
       "4 2018-01-01  2018-01-01 17:00:00.000             17  2018-01-01 17:15:00.000   \n",
       "\n",
       "   WAIT_TIME_MAX  NB_UNITS  GUEST_CARRIED  CAPACITY  ADJUST_CAPACITY  \\\n",
       "0              0       2.0            0.0     0.000             0.00   \n",
       "1              5      18.0          148.0   254.749           254.75   \n",
       "2              0       1.0            0.0     0.000             0.00   \n",
       "3              5       1.0           46.0   250.001           250.00   \n",
       "4              5      15.0           92.0   211.500           198.25   \n",
       "\n",
       "   OPEN_TIME  ...  humidity  wind_speed  wind_deg clouds_all weather_id  \\\n",
       "0          0  ...        76        7.94       231         34        802   \n",
       "1         15  ...        76        7.94       231         34        802   \n",
       "2          0  ...        76        7.94       231         34        802   \n",
       "3         15  ...        76        7.94       231         34        802   \n",
       "4         15  ...        76        7.94       231         34        802   \n",
       "\n",
       "   weather_main  weather_description  weather_icon  REF_CLOSING_DESCRIPTION  \\\n",
       "0        Clouds     scattered clouds           03n               No Closure   \n",
       "1        Clouds     scattered clouds           03n               No Closure   \n",
       "2        Clouds     scattered clouds           03n               No Closure   \n",
       "3        Clouds     scattered clouds           03n               No Closure   \n",
       "4        Clouds     scattered clouds           03n               No Closure   \n",
       "\n",
       "     month  \n",
       "0  January  \n",
       "1  January  \n",
       "2  January  \n",
       "3  January  \n",
       "4  January  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all columns that are entirely null excpet for REF_CLOSING_DESCRIPTION which is important for indicating closures\n",
    "\n",
    "master_merged_4['REF_CLOSING_DESCRIPTION']= master_merged_4['REF_CLOSING_DESCRIPTION'].fillna('No Closure')\n",
    "\n",
    "# now removing all other columns that are majority na\n",
    "\n",
    "threshold = 0.8\n",
    "cols_to_drop = master_merged_4.columns[master_merged_4.isna().sum()/len(master_merged_4) > threshold]\n",
    "df = master_merged_4.drop(columns = cols_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {cols_to_drop.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e80079",
   "metadata": {},
   "source": [
    "# Remove extreme outliers for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669d10db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: DEB_TIME_HOUR, has 0 outliers\n",
      "Column: WAIT_TIME_MAX, has 48299 outliers\n",
      "Column: NB_UNITS, has 200686 outliers\n",
      "Column: GUEST_CARRIED, has 19279 outliers\n",
      "Column: CAPACITY, has 0 outliers\n",
      "Column: ADJUST_CAPACITY, has 0 outliers\n",
      "Column: OPEN_TIME, has 0 outliers\n",
      "Column: UP_TIME, has 0 outliers\n",
      "Column: DOWNTIME, has 79346 outliers\n",
      "Column: NB_MAX_UNIT, has 108040 outliers\n",
      "Column: attendance, has 0 outliers\n",
      "Column: temp, has 0 outliers\n",
      "Column: dew_point, has 0 outliers\n",
      "Column: feels_like, has 0 outliers\n",
      "Column: temp_min, has 0 outliers\n",
      "Column: temp_max, has 0 outliers\n",
      "Column: pressure, has 0 outliers\n",
      "Column: humidity, has 0 outliers\n",
      "Column: wind_speed, has 6975 outliers\n",
      "Column: wind_deg, has 0 outliers\n",
      "Column: clouds_all, has 0 outliers\n",
      "Column: weather_id, has 207926 outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORK_DATE</th>\n",
       "      <th>DEB_TIME</th>\n",
       "      <th>DEB_TIME_HOUR</th>\n",
       "      <th>FIN_TIME</th>\n",
       "      <th>WAIT_TIME_MAX</th>\n",
       "      <th>NB_UNITS</th>\n",
       "      <th>GUEST_CARRIED</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>ADJUST_CAPACITY</th>\n",
       "      <th>OPEN_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "      <th>REF_CLOSING_DESCRIPTION</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312872</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 19:00:00.000</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-06-01 19:15:00.000</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312873</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 15:00:00.000</td>\n",
       "      <td>15</td>\n",
       "      <td>2018-06-01 15:15:00.000</td>\n",
       "      <td>30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>280.50</td>\n",
       "      <td>263.50</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312874</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 20:30:00.000</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-06-01 20:45:00.000</td>\n",
       "      <td>40</td>\n",
       "      <td>12.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>101.25</td>\n",
       "      <td>101.25</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312875</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 16:30:00.000</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-06-01 16:45:00.000</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>526.25</td>\n",
       "      <td>438.50</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>No Closure</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312877</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2018-06-01 13:45:00.000</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-06-01 14:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>804</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>04n</td>\n",
       "      <td>Fermeture Opérationnelle</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WORK_DATE                 DEB_TIME  DEB_TIME_HOUR  \\\n",
       "312872 2018-06-01  2018-06-01 19:00:00.000             19   \n",
       "312873 2018-06-01  2018-06-01 15:00:00.000             15   \n",
       "312874 2018-06-01  2018-06-01 20:30:00.000             20   \n",
       "312875 2018-06-01  2018-06-01 16:30:00.000             16   \n",
       "312877 2018-06-01  2018-06-01 13:45:00.000             13   \n",
       "\n",
       "                       FIN_TIME  WAIT_TIME_MAX  NB_UNITS  GUEST_CARRIED  \\\n",
       "312872  2018-06-01 19:15:00.000             15       2.0           50.0   \n",
       "312873  2018-06-01 15:15:00.000             30      62.0          155.0   \n",
       "312874  2018-06-01 20:45:00.000             40      12.0           69.0   \n",
       "312875  2018-06-01 16:45:00.000             15       5.0          283.0   \n",
       "312877  2018-06-01 14:00:00.000              0       0.0            0.0   \n",
       "\n",
       "        CAPACITY  ADJUST_CAPACITY  OPEN_TIME  ...  humidity  wind_speed  \\\n",
       "312872     75.00            75.00         15  ...        94        1.54   \n",
       "312873    280.50           263.50         15  ...        94        1.54   \n",
       "312874    101.25           101.25         15  ...        94        1.54   \n",
       "312875    526.25           438.50         15  ...        94        1.54   \n",
       "312877      0.00             0.00          0  ...        94        1.54   \n",
       "\n",
       "        wind_deg clouds_all weather_id  weather_main  weather_description  \\\n",
       "312872       200         99        804        Clouds      overcast clouds   \n",
       "312873       200         99        804        Clouds      overcast clouds   \n",
       "312874       200         99        804        Clouds      overcast clouds   \n",
       "312875       200         99        804        Clouds      overcast clouds   \n",
       "312877       200         99        804        Clouds      overcast clouds   \n",
       "\n",
       "        weather_icon   REF_CLOSING_DESCRIPTION  month  \n",
       "312872           04n                No Closure   June  \n",
       "312873           04n                No Closure   June  \n",
       "312874           04n                No Closure   June  \n",
       "312875           04n                No Closure   June  \n",
       "312877           04n  Fermeture Opérationnelle   June  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "filtering out extreme outliers for numerical features by\n",
    "removing any data points outside of 3*IQR for each numerical column\n",
    "\"\"\"\n",
    "df_clean= df.copy()\n",
    "\n",
    "#get the numerical columns\n",
    "numerical_cols = df_clean.select_dtypes(include=['number']).columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    Q1  = df_clean[col].quantile(0.25)\n",
    "    Q3  = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 3*IQR\n",
    "    upper_bound = Q3 + 3*IQR\n",
    "\n",
    "    #count outliers before removal\n",
    "    outlier_count = len(df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)])\n",
    "    print(f\"Column: {col}, has {outlier_count} outliers\")\n",
    "\n",
    "    #remove the outliers\n",
    "    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d890f",
   "metadata": {},
   "source": [
    "# Scaling our numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c303b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\script.pc #93\\AppData\\Local\\Temp\\ipykernel_21132\\1102225279.py:7: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance columns: ['PARK', 'weather_main', 'weather_description', 'weather_icon', 'REF_CLOSING_DESCRIPTION', 'month']\n"
     ]
    }
   ],
   "source": [
    "#finding imbalance categories\n",
    "\n",
    "#converting dateetime strings into datetime dtype\n",
    "df_clean['DEB_TIME']= pd.to_datetime(df_clean['DEB_TIME'])\n",
    "df_clean['FIN_TIME']= pd.to_datetime(df_clean['FIN_TIME'])\n",
    "\n",
    "categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "imbalance_cols = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    value_counts = df_clean[col].value_counts()\n",
    "    percentages = value_counts / len(df_clean) * 100\n",
    "\n",
    "    #check highest occuring category and lowest occurring category to find imbalance ratio\n",
    "    imbalance_ration =  (percentages.max()-percentages.min())\n",
    "\n",
    "    #check if imbalance ratio is 5 > times\n",
    "    if imbalance_ration > 5:\n",
    "        imbalance_cols.append(col)\n",
    "print(f\"Imbalance columns: {imbalance_cols}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082f15f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (1893178, 32)\n",
      "Train Set Shape: (1135906, 32)\n",
      "Validation Set hape: (378636, 32)\n",
      "Test Set Shape: (378636, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split our data before scaling to avoid data leakage\n",
    "train_df, test_df = train_test_split(df_clean, \n",
    "                                     test_size=0.4, \n",
    "                                     random_state=42,\n",
    "                                     stratify=df_clean[['PARK','weather_main', 'weather_description','weather_icon','REF_CLOSING_DESCRIPTION']])\n",
    "\n",
    "val_df, test_df = train_test_split(test_df, \n",
    "                                     test_size=0.5, \n",
    "                                     random_state=42,\n",
    "                                     stratify=test_df[['PARK','weather_main', 'weather_description','weather_icon','REF_CLOSING_DESCRIPTION']]) \n",
    "\n",
    "print(f\"Original Shape: {df_clean.shape}\")\n",
    "print(f\"Train Set Shape: {train_df.shape}\")\n",
    "print(f\"Validation Set hape: {val_df.shape}\")\n",
    "print(f\"Test Set Shape: {test_df.shape}\")\n",
    "\n",
    "numerical_cols = df_clean.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e842467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1135906, 21)\n",
      "Validation set shape: (378636, 21)\n",
      "Test set shape: (378636, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_cols = train_df.select_dtypes(include=['number']).columns\n",
    "# even though its numeric it should be treated as categorical\n",
    "numerical_cols = numerical_cols.drop('DEB_TIME_HOUR')\n",
    "\n",
    "# scale fit on train set ONLY\n",
    "train_df_scaled = scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "# scale transform on val and test set using the same scaler fit on train set\n",
    "val_df_scaled = scaler.transform(val_df[numerical_cols])\n",
    "test_df_scaled = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "train_df_scaled = pd.DataFrame(train_df_scaled, columns = numerical_cols, index = train_df.index)\n",
    "val_df_scaled = pd.DataFrame(val_df_scaled, columns = numerical_cols, index = val_df.index)\n",
    "test_df_scaled = pd.DataFrame(test_df_scaled, columns = numerical_cols, index = test_df.index)\n",
    "\n",
    "print(f\"Train set shape: {train_df_scaled.shape}\")\n",
    "print(f\"Validation set shape: {val_df_scaled.shape}\")\n",
    "print(f\"Test set shape: {test_df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba7267",
   "metadata": {},
   "source": [
    "# Categorical Enconding\n",
    "One hot encoding because we dont have any ordinal categories for ordinal or binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9778e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\script.pc #93\\AppData\\Local\\Temp\\ipykernel_21132\\3024805385.py:3: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1135906, 70)\n",
      "Validation set shape: (378636, 70)\n",
      "Test set shape: (378636, 70)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# adding hours to categorical\n",
    "categorical_cols.append('DEB_TIME_HOUR')\n",
    "\n",
    "# fit OHE on the train set ONLY\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore', drop = 'first')\n",
    "train_df_ohe = ohe.fit_transform(train_df[categorical_cols])\n",
    "\n",
    "# transform val and test set using the same OHE fit on train set\n",
    "val_df_ohe = ohe.transform(val_df[categorical_cols])\n",
    "test_df_ohe = ohe.transform(test_df[categorical_cols])\n",
    "\n",
    "# transform ohe matrices into dataframes\n",
    "ohe_columns = ohe.get_feature_names_out(categorical_cols)\n",
    "train_df_ohe = pd.DataFrame(train_df_ohe.toarray(), columns = ohe_columns, index = train_df.index)\n",
    "val_df_ohe = pd.DataFrame(val_df_ohe.toarray(), columns=ohe_columns, index = val_df.index)\n",
    "test_df_ohe = pd.DataFrame(test_df_ohe.toarray(), columns=ohe_columns, index = test_df.index)\n",
    "\n",
    "print(f\"Train set shape: {train_df_ohe.shape}\")\n",
    "print(f\"Validation set shape: {val_df_ohe.shape}\")\n",
    "print(f\"Test set shape: {test_df_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e667102",
   "metadata": {},
   "source": [
    "# Combing Scaled and Encoded Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382a3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Original data shape: (1893178, 32) \n",
      "=============================================================================\n",
      "Checking Final Train set shape: (1135906, 91)\n",
      "Checking Final Validation set shape: (378636, 91)\n",
      "Checking Final Test set shape: (378636, 91)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAIT_TIME_MAX</th>\n",
       "      <th>NB_UNITS</th>\n",
       "      <th>GUEST_CARRIED</th>\n",
       "      <th>CAPACITY</th>\n",
       "      <th>ADJUST_CAPACITY</th>\n",
       "      <th>OPEN_TIME</th>\n",
       "      <th>UP_TIME</th>\n",
       "      <th>DOWNTIME</th>\n",
       "      <th>NB_MAX_UNIT</th>\n",
       "      <th>attendance</th>\n",
       "      <th>...</th>\n",
       "      <th>DEB_TIME_HOUR_13</th>\n",
       "      <th>DEB_TIME_HOUR_14</th>\n",
       "      <th>DEB_TIME_HOUR_15</th>\n",
       "      <th>DEB_TIME_HOUR_16</th>\n",
       "      <th>DEB_TIME_HOUR_17</th>\n",
       "      <th>DEB_TIME_HOUR_18</th>\n",
       "      <th>DEB_TIME_HOUR_19</th>\n",
       "      <th>DEB_TIME_HOUR_20</th>\n",
       "      <th>DEB_TIME_HOUR_21</th>\n",
       "      <th>DEB_TIME_HOUR_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454155</th>\n",
       "      <td>-0.779582</td>\n",
       "      <td>-0.933130</td>\n",
       "      <td>-0.885929</td>\n",
       "      <td>-0.989296</td>\n",
       "      <td>-0.971058</td>\n",
       "      <td>-1.323598</td>\n",
       "      <td>-1.323598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.805367</td>\n",
       "      <td>2.398246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093050</th>\n",
       "      <td>-0.518994</td>\n",
       "      <td>0.793474</td>\n",
       "      <td>0.422415</td>\n",
       "      <td>0.338631</td>\n",
       "      <td>0.388782</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505984</td>\n",
       "      <td>-1.171366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451793</th>\n",
       "      <td>-0.779582</td>\n",
       "      <td>-0.831565</td>\n",
       "      <td>-0.885929</td>\n",
       "      <td>-0.989296</td>\n",
       "      <td>-0.971058</td>\n",
       "      <td>-1.323598</td>\n",
       "      <td>-1.323598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.887326</td>\n",
       "      <td>-0.190363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617989</th>\n",
       "      <td>-0.779582</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.616271</td>\n",
       "      <td>1.030621</td>\n",
       "      <td>1.219952</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.805367</td>\n",
       "      <td>-1.067939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330062</th>\n",
       "      <td>-0.779582</td>\n",
       "      <td>1.504429</td>\n",
       "      <td>-0.796043</td>\n",
       "      <td>2.444302</td>\n",
       "      <td>2.753377</td>\n",
       "      <td>0.627179</td>\n",
       "      <td>0.627179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>1.245530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         WAIT_TIME_MAX  NB_UNITS  GUEST_CARRIED  CAPACITY  ADJUST_CAPACITY  \\\n",
       "454155       -0.779582 -0.933130      -0.885929 -0.989296        -0.971058   \n",
       "3093050      -0.518994  0.793474       0.422415  0.338631         0.388782   \n",
       "1451793      -0.779582 -0.831565      -0.885929 -0.989296        -0.971058   \n",
       "2617989      -0.779582 -0.730000      -0.616271  1.030621         1.219952   \n",
       "1330062      -0.779582  1.504429      -0.796043  2.444302         2.753377   \n",
       "\n",
       "         OPEN_TIME   UP_TIME  DOWNTIME  NB_MAX_UNIT  attendance  ...  \\\n",
       "454155   -1.323598 -1.323598       0.0    -0.805367    2.398246  ...   \n",
       "3093050   0.766520  0.766520       0.0     0.505984   -1.171366  ...   \n",
       "1451793  -1.323598 -1.323598       0.0    -0.887326   -0.190363  ...   \n",
       "2617989   0.766520  0.766520       0.0    -0.805367   -1.067939  ...   \n",
       "1330062   0.627179  0.627179       0.0     0.997741    1.245530  ...   \n",
       "\n",
       "         DEB_TIME_HOUR_13  DEB_TIME_HOUR_14  DEB_TIME_HOUR_15  \\\n",
       "454155                0.0               0.0               0.0   \n",
       "3093050               0.0               0.0               0.0   \n",
       "1451793               0.0               0.0               0.0   \n",
       "2617989               0.0               1.0               0.0   \n",
       "1330062               0.0               0.0               0.0   \n",
       "\n",
       "         DEB_TIME_HOUR_16  DEB_TIME_HOUR_17  DEB_TIME_HOUR_18  \\\n",
       "454155                1.0               0.0               0.0   \n",
       "3093050               1.0               0.0               0.0   \n",
       "1451793               0.0               0.0               0.0   \n",
       "2617989               0.0               0.0               0.0   \n",
       "1330062               0.0               0.0               0.0   \n",
       "\n",
       "         DEB_TIME_HOUR_19  DEB_TIME_HOUR_20  DEB_TIME_HOUR_21  \\\n",
       "454155                0.0               0.0               0.0   \n",
       "3093050               0.0               0.0               0.0   \n",
       "1451793               1.0               0.0               0.0   \n",
       "2617989               0.0               0.0               0.0   \n",
       "1330062               0.0               0.0               1.0   \n",
       "\n",
       "         DEB_TIME_HOUR_22  \n",
       "454155                0.0  \n",
       "3093050               0.0  \n",
       "1451793               0.0  \n",
       "2617989               0.0  \n",
       "1330062               0.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_final = pd.concat([train_df_scaled, train_df_ohe], axis = 1)\n",
    "val_df_final = pd.concat([val_df_scaled, val_df_ohe], axis = 1)\n",
    "test_df_final = pd.concat([test_df_scaled, test_df_ohe], axis = 1)  \n",
    "\n",
    "print(f\"Checking Original data shape: {df_clean.shape} \")\n",
    "print(\"=============================================================================\")\n",
    "print(f\"Checking Final Train set shape: {train_df_final.shape}\")\n",
    "print(f\"Checking Final Validation set shape: {val_df_final.shape}\")\n",
    "print(f\"Checking Final Test set shape: {test_df_final.shape}\")\n",
    "\n",
    "display(train_df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea5c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final.to_parquet('../data/processed_data/train_main.parquet', index=False)\n",
    "val_df_final.to_parquet('../data/processed_data/val_main.parquet', index=False)\n",
    "test_df_final.to_parquet('../data/processed_data/test_main.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590b27c",
   "metadata": {},
   "source": [
    "# Combining only Scaled Dataframe back to Main\n",
    "For CatBoost later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4a847a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shapes:\n",
      "Train set shape:  (1135906, 32)\n",
      "Validation set shape:  (378636, 32)\n",
      "Test set shape:  (378636, 32)\n",
      "Shapes after scaling\n",
      "Train set shape:  (1135906, 32)\n",
      "Validation set shape:  (378636, 32)\n",
      "Test set shape:  (378636, 32)\n"
     ]
    }
   ],
   "source": [
    "# replacing only the numerical columns in the original dataframes with the scaled versions\n",
    "train_df_catboost = train_df.copy()\n",
    "val_df_catboost = val_df.copy()\n",
    "test_df_catboost = test_df.copy()\n",
    "\n",
    "train_df_catboost[train_df_scaled.columns] = train_df_scaled\n",
    "val_df_catboost[val_df_scaled.columns] = val_df_scaled\n",
    "test_df_catboost[test_df_scaled.columns] = test_df_scaled\n",
    "\n",
    "print(\"Original dataframe shapes:\")\n",
    "print(\"Train set shape: \", train_df.shape)\n",
    "print(\"Validation set shape: \", val_df.shape)\n",
    "print(\"Test set shape: \", test_df.shape)\n",
    "\n",
    "print(\"Shapes after scaling\")\n",
    "print(\"Train set shape: \", train_df_catboost.shape)\n",
    "print(\"Validation set shape: \", val_df_catboost.shape)\n",
    "print(\"Test set shape: \", test_df_catboost.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6dfcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_catboost.to_parquet('../data/processed_data/train_catboost.parquet', index=False)\n",
    "val_df_catboost.to_parquet('../data/processed_data/val_catboost.parquet', index=False)\n",
    "test_df_catboost.to_parquet('../data/processed_data/test_catboost.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
